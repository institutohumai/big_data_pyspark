{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["8ZUAlAWCRvtD","R7IHfTpTQ38i","DsAocF7UrU9z","GhDBezDJrywP","Lo5bA5dMRUte"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<img src='https://th.bing.com/th/id/R.38bf6a6c11d543d1015e724f002798a4?rik=25ujuy3w4NDXtg&pid=ImgRaw&r=0' width='210'/>"],"metadata":{"id":"mWMdVoKiECo0"}},{"cell_type":"markdown","source":["**Apache Spark** es un open-source framework para ejecutar codigo de manera paralela en maquinas diferentes, esto ultimo se conoce como procesamiento distribuido en un cluster. Esta casi en su totalidad escrito en Scala pero podemos usar Spark escribiendo codigo en Python con la libreria PySpark."],"metadata":{"id":"G0IKjmYd0aEc"}},{"cell_type":"markdown","source":["# Spark Stack\n","---"],"metadata":{"id":"d4RFBh-amYvu"}},{"cell_type":"markdown","source":["<img src='https://github.com/engcarlosperezmolero/resources_and_tools/blob/main/imgs/pyspark-class/spark-stack.png?raw=true' />"],"metadata":{"id":"9gQeC6zVn7ZK"}},{"cell_type":"markdown","source":["# Conceptos Claves\n","---"],"metadata":{"id":"zRutChA0n3Ar"}},{"cell_type":"markdown","source":["### SparkSession (tambien conocido como ```spark```)\n","Una clase definida en el paquete de ```pyspark.sql```. Esta clase es el punto de acceso unificado para programar Spark usando la API Estructurada (DataFrame y Dataset). Se usa normalmente para crear Dataframes, registrar Dataframes como tablas, ejecutar SQL sobre tablas y leer archivos parquet. Desde esta clase puedes acceder tambien al SparkContext.\n","\n","Se le denomina \"unificado\" porque agrupa los siguientes puntos de acceso a otras funcionalidades de Spark:\n","- Spark Context\n","- SQL Context\n","- Hive Context\n","- Streaming Context\n","- Spark Configuration\n"],"metadata":{"id":"zt8AE4gUpCDC"}},{"cell_type":"markdown","source":["### SparkContext (tambien conocido como ```sc```)\n","Una clase definida en el paquete de ```pyspark``` y representa la conexion al Spark Cluster. Es el punto de acceso principal para usar el motor de Spark. Mantiene una conexion con el \"cluster manager\" de Spark y puede ser usado para crear RDD y hacer broadcasting de variables en ese cluster. Todas las aplicaciones de Spark (incluyendo PySpark Shell y programas de Python aislados) se ejecutan como un conjunto de procesos independientes. Estos procesos son coordinados por el SparkContext  en un programa driver.\n"],"metadata":{"id":"cj9J9wyqESez"}},{"cell_type":"markdown","source":["### Driver (archivo .py o notebook .ipynb)\n","Para enviar (submit) un programa de Python a Spark, necesitars escribir un programa Driver con algun Lenguaje que proporcione la conexion a spark (como PySpark). Este programa esta a cargo de crear el SparkContext, RDD y Dataframes.\n"],"metadata":{"id":"lyT-QRZXEYAD"}},{"cell_type":"markdown","source":["### Worker (Recursos = Procesadores | Memoria RAM)\n","En el entorno del cluster de Spark, existen dos tipos de nodos:\n","- 1 Master (o 2 para hablar de alta disponibilidad, a veces mas)\n","- Conjunto de Workers.\n","\n","Worker es cualquier nodo capaz de ejecutar programas en el cluster. Si un proceso es disparado para cierta aplicacion, entonces esta aplicacion adquiere executors y workers, los cuales llevan a cabo la ejecucion de las tareas de la aplicacion de Spark.\n","\n","Tambien se conocen como nodo Slave (Esclavo).\n"],"metadata":{"id":"6drbOzr-EcPh"}},{"cell_type":"markdown","source":["### Executor (procesos dentro de los Workers)\n","Son los procesos que existen dentro de los Workers donde se llevan a cabo las tareas designadas. Cada worker genera subprocesos de python donde se envia el codigo del usuario y los datos para ser procesados.\n"],"metadata":{"id":"9O4qZv-dEf-0"}},{"cell_type":"markdown","source":["\n","\n","### Cluster Manager\n","El nodo master tambien es conocido como el cluster manager. Este se encargara administrar el cluster de servidores necesario para que Spark lleve a cabo las tareas. El cluster manager asigna recursos a cada aplicacion dentro del programa driver. Hay 5 tipos de Cluster Manager aceptados por Spark actualmente:\n","- Standalone: entorno de cluster built-in de Spark.\n","- Mesos: un kernel de Sistemas Distribuidos.\n","- Hadoop YARN (Yet Another Resource Negotiator).\n","- Kubernetes\n","- Amazon EC2"],"metadata":{"id":"WY2aRUqSEjrA"}},{"cell_type":"markdown","source":["<img src='https://github.com/engcarlosperezmolero/resources_and_tools/blob/main/imgs/pyspark-class/spark-app-arch.png?raw=true' />"],"metadata":{"id":"oAXLiwD8Bm1e"}},{"cell_type":"markdown","source":["### Particiones\n","Para permitir a cada executor realizar trabajos en paralelo, Spark divide los datos en chunks (division logica de la data) llamados particiones. Una particion es la unidad basica de paralelismo en Spark que esta en una maquina fisica (nodo) de tu cluster. Con DataFrames no manipularas particiones manualmente o individualmente, solo especificaras transformaciones de alto nivel. Spark tomara tus instrucciones y se encargara de hacer el trabajo de bajo nivel (usando la RDD API)."],"metadata":{"id":"saP3IZZIR8yP"}},{"cell_type":"markdown","source":["# RDD: Resilient Distributed Dataset\n","---"],"metadata":{"id":"FtUHqqoTFipA"}},{"cell_type":"markdown","source":["Es literalmente una coleccion de particiones que a su vez es una coleccion de objetos, cualquier clase de objeto puede estar presente, es muy flexible en comparación al Dataframe (el cual es una coleccion de columnas) pero tambien esta caracteristica lo hace mas dificil de operar. Spark tiene 3 tipos de abstracciones de datos RDD es solo 1 de las 3 que existen (siendo las otras dos Dataframes y Datasets).\n","\n","\n","- Se denota como RDD[T], cada elemento tiene tipo T.\n"],"metadata":{"id":"U6DacAkcm-A_"}},{"cell_type":"code","source":["!pip install pyspark -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ps4FzalEGVxe","outputId":"96ab1594-7075-4c2a-d4dc-e87724859e94","executionInfo":{"status":"ok","timestamp":1689774269485,"user_tz":180,"elapsed":47544,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder\\\n","        .master(\"local\")\\\n","        .appName(\"Colab\")\\\n","        .config('spark.ui.port', '4050')\\\n","        .getOrCreate()\n","\n","# .config(\"spark.sql.repl.eagerEval.enabled\", \"True\")\\\n","\n","sc = spark.sparkContext"],"metadata":{"id":"TfGDirUdGWed","executionInfo":{"status":"ok","timestamp":1689774280329,"user_tz":180,"elapsed":10853,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["collection = [1, \"two\", 3.0, (\"four\", 4), {\"five\": 5}] # entero, texto, tupla, diccionario\n","collection_rdd = sc.parallelize(collection) # este es el comando que se usa para crear el RDD a partir de una lista"],"metadata":{"id":"fZ9343kAJBob","executionInfo":{"status":"ok","timestamp":1689774280764,"user_tz":180,"elapsed":439,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["type(collection_rdd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tjUaG--PzK_","outputId":"8f9ae6c2-6164-4a17-f344-0a7e124d5e2c","executionInfo":{"status":"ok","timestamp":1689774280765,"user_tz":180,"elapsed":19,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.rdd.RDD"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["collection_rdd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-zU_lDcP0pJ","outputId":"733d1830-874f-467a-9c1e-46c849c4fe40","executionInfo":{"status":"ok","timestamp":1689774280766,"user_tz":180,"elapsed":10,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:287"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["collection_rdd.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eT52IxMP5TC","outputId":"001f8b51-b0b0-4773-eefc-cfd50e3b11b7","executionInfo":{"status":"ok","timestamp":1689774282327,"user_tz":180,"elapsed":1567,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 'two', 3.0, ('four', 4), {'five': 5}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["[i for i in dir(collection_rdd) if not i.startswith(\"_\")]"],"metadata":{"id":"aSwLYw7cP9oI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689774282328,"user_tz":180,"elapsed":14,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}},"outputId":"3ad3f54e-5080-44de-a7de-611bca077f8e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['aggregate',\n"," 'aggregateByKey',\n"," 'barrier',\n"," 'cache',\n"," 'cartesian',\n"," 'checkpoint',\n"," 'cleanShuffleDependencies',\n"," 'coalesce',\n"," 'cogroup',\n"," 'collect',\n"," 'collectAsMap',\n"," 'collectWithJobGroup',\n"," 'combineByKey',\n"," 'context',\n"," 'count',\n"," 'countApprox',\n"," 'countApproxDistinct',\n"," 'countByKey',\n"," 'countByValue',\n"," 'ctx',\n"," 'distinct',\n"," 'filter',\n"," 'first',\n"," 'flatMap',\n"," 'flatMapValues',\n"," 'fold',\n"," 'foldByKey',\n"," 'foreach',\n"," 'foreachPartition',\n"," 'fullOuterJoin',\n"," 'getCheckpointFile',\n"," 'getNumPartitions',\n"," 'getResourceProfile',\n"," 'getStorageLevel',\n"," 'glom',\n"," 'groupBy',\n"," 'groupByKey',\n"," 'groupWith',\n"," 'has_resource_profile',\n"," 'histogram',\n"," 'id',\n"," 'intersection',\n"," 'isCheckpointed',\n"," 'isEmpty',\n"," 'isLocallyCheckpointed',\n"," 'is_cached',\n"," 'is_checkpointed',\n"," 'join',\n"," 'keyBy',\n"," 'keys',\n"," 'leftOuterJoin',\n"," 'localCheckpoint',\n"," 'lookup',\n"," 'map',\n"," 'mapPartitions',\n"," 'mapPartitionsWithIndex',\n"," 'mapPartitionsWithSplit',\n"," 'mapValues',\n"," 'max',\n"," 'mean',\n"," 'meanApprox',\n"," 'min',\n"," 'name',\n"," 'partitionBy',\n"," 'partitioner',\n"," 'persist',\n"," 'pipe',\n"," 'randomSplit',\n"," 'reduce',\n"," 'reduceByKey',\n"," 'reduceByKeyLocally',\n"," 'repartition',\n"," 'repartitionAndSortWithinPartitions',\n"," 'rightOuterJoin',\n"," 'sample',\n"," 'sampleByKey',\n"," 'sampleStdev',\n"," 'sampleVariance',\n"," 'saveAsHadoopDataset',\n"," 'saveAsHadoopFile',\n"," 'saveAsNewAPIHadoopDataset',\n"," 'saveAsNewAPIHadoopFile',\n"," 'saveAsPickleFile',\n"," 'saveAsSequenceFile',\n"," 'saveAsTextFile',\n"," 'setName',\n"," 'sortBy',\n"," 'sortByKey',\n"," 'stats',\n"," 'stdev',\n"," 'subtract',\n"," 'subtractByKey',\n"," 'sum',\n"," 'sumApprox',\n"," 'take',\n"," 'takeOrdered',\n"," 'takeSample',\n"," 'toDF',\n"," 'toDebugString',\n"," 'toLocalIterator',\n"," 'top',\n"," 'treeAggregate',\n"," 'treeReduce',\n"," 'union',\n"," 'unpersist',\n"," 'values',\n"," 'variance',\n"," 'withResources',\n"," 'zip',\n"," 'zipWithIndex',\n"," 'zipWithUniqueId']"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# Transformaciones y Acciones\n","---"],"metadata":{"id":"QweAJMujQelE"}},{"cell_type":"markdown","source":["## Transformaciones (Lazy Evaluated)\n","Ya que en spark las estructuras de datos fundamentales son inmutables, la unica manera de modificar un estructura (RDD o Dataframe) es a traves de una transformacion, esta es una operacion que crea un nuevo RDD o Dataframe.\n","\n","\n","- Entonces transforma un RDD de entrada a un RDD (o varios) de salida.\n","- Una transformacion es basicamente una funcion.\n","- Si un RDD falla durante una transformacion, el linaje de los datos (data lineage descrito por DAG) reconstruye el RDD.\n"],"metadata":{"id":"ugEg5n1IQjnE"}},{"cell_type":"code","source":["list_1 = [1, 2, 3, 4]\n","rdd_1 = sc.parallelize(list_1) # creando el RDD[int]"],"metadata":{"id":"1v9TfQTNQ3xf","executionInfo":{"status":"ok","timestamp":1689774282328,"user_tz":180,"elapsed":9,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["rdd_2 = rdd_1.map(lambda x: x * 10) # al hacer una transformacion creamos el rdd_2 a partir de rdd_1"],"metadata":{"id":"gNZNUmljTu9c","executionInfo":{"status":"ok","timestamp":1689774282329,"user_tz":180,"elapsed":9,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Narrow Dependencies Transformations (1 a 1)\n","Son aquellas en donde cada particion de entrada despues de transformada correspondera a solo una particion de salida. El ejemplo de arriba (map) es una Narrow Transformation.\n","\n","<img src='https://github.com/engcarlosperezmolero/resources_and_tools/blob/main/imgs/pyspark-class/narrow_transformation.png?raw=true' />\n","\n"],"metadata":{"id":"Ys2o2jneUcXh"}},{"cell_type":"markdown","source":["### Wide Dependencies Transformations (Shuffle - 1 a N)\n","Son aquellas en donde al menos una de las particiones de entrada despues de transformada correspondera a varias particiones de salida. Tambien se llama Shuffle porque Spark intercambiara particiones a traves de todo el cluster. Mientras que con las Narrow Transformations Spark automaticamente hara una operacion llamada Pipelining (en donde todo sucede en memoria), para los Shuffles Spark escribira los resultados en disco.\n","\n","<img src='https://github.com/engcarlosperezmolero/resources_and_tools/blob/main/imgs/pyspark-class/wide_transformation.png?raw=true' />"],"metadata":{"id":"G5XIEfJ2meqy"}},{"cell_type":"markdown","source":["### Lazy Evaluation\n","Esto es simplemente que Spark esperar para ejecutar una serie de Transformaciones (representadas en forma de DAG) hasta que sea realmente necesario (dado que se realizo una Acción). Gracias a esto Spark es capaz de optimizar el flujo de la data de principio a fin, sin tener nosotros que preocuparnos por eso.\n","- Leer un archivo, transformarlo y luego filtrarlo, no sera mas eficiente que filtrarlo y luego transformarlo."],"metadata":{"id":"XiTKb5juk6Xd"}},{"cell_type":"markdown","source":["### ¿Por qué importa saber la diferencia entre ambas transformaciones?"],"metadata":{"id":"8ZUAlAWCRvtD"}},{"cell_type":"code","source":["apariciones_desordenadas = [(\"a\", 1), (\"b\", 3), (\"a\", 2), (\"b\", 5), (\"c\", 2), (\"a\", 2), (\"c\", 3)]\n","rdd_apariciones = sc.parallelize(apariciones_desordenadas) # RDD[(string, int)]"],"metadata":{"id":"8cj2DeSXme0w","executionInfo":{"status":"ok","timestamp":1689774282329,"user_tz":180,"elapsed":9,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["rdd_apariciones.saveAsTextFile('./apariciones')"],"metadata":{"id":"4QkA0bZ2on3z","executionInfo":{"status":"ok","timestamp":1689774284004,"user_tz":180,"elapsed":1683,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# opcion 1 (no recomendada ya que causa mas suffling)\n","rdd_apariciones.groupByKey().mapValues(lambda values: sum(values)).collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31pSS7-2nHmH","outputId":"fecf7dfc-7ad2-4939-9f33-ad63faa66bc7","executionInfo":{"status":"ok","timestamp":1689774287196,"user_tz":180,"elapsed":3196,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('a', 5), ('b', 8), ('c', 5)]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# opcion 2 (casi siempre el reduceByKey sera mas eficiente que el patron de arriba)\n","rdd_apariciones.reduceByKey(lambda x, y: x + y).collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TfkFuD5yn8Mc","outputId":"91699aef-8693-4f96-d195-9efe1440d17a","executionInfo":{"status":"ok","timestamp":1689774288813,"user_tz":180,"elapsed":1620,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('a', 5), ('b', 8), ('c', 5)]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Acciones\n","Estas son operaciones o funciones de un RDD que producen valores distintos de un RDD o Dataframe. Son muy importantes ya que estas disparan la ejecucion de los ya construidos lazy RDDs a traves de transformaciones.\n","\n","Las acciones pueden convertir un RDD en cosas tangibles como:\n","- un archivo guardado.\n","- un entero.\n","- un conteo de elementos.\n","- una lista o un diccionario."],"metadata":{"id":"R7IHfTpTQ38i"}},{"cell_type":"code","source":["rdd_2.count() # produce un entero"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hFLIqn9jVcs","outputId":"593bb52d-beb2-4c6b-ad18-e210940883a4","executionInfo":{"status":"ok","timestamp":1689774289326,"user_tz":180,"elapsed":518,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["rdd_2.collect() # produce una lista de enteros (NO USAR EN RDD GRANDES en servidores de produccion), usar take en su lugar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6Oo0utjjYZS","outputId":"cfa9d84c-26f2-48b4-891a-01ce934155c8","executionInfo":{"status":"ok","timestamp":1689774289899,"user_tz":180,"elapsed":575,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[10, 20, 30, 40]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["rdd_2.take(2) # DataFrame.take(N) devuelve una lista de las primeras N filas como una lista de objetos Row"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcYFfZH1kE6H","outputId":"c5b069b3-0ffc-4ad7-acb3-6dd0986e73e1","executionInfo":{"status":"ok","timestamp":1689774290251,"user_tz":180,"elapsed":354,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[10, 20]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["rdd_2.getNumPartitions() # un entero"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ahXqwFJ1ZYNn","outputId":"200f9eff-2753-4bbb-edd7-6804c8c18de9","executionInfo":{"status":"ok","timestamp":1689774290251,"user_tz":180,"elapsed":2,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["rdd_2.saveAsTextFile(\"./rdd_2\",) # produce archivos guardados en este caso 2"],"metadata":{"id":"R66TH4vUjZ87","executionInfo":{"status":"ok","timestamp":1689774290914,"user_tz":180,"elapsed":665,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["rdd_2.coalesce(1).saveAsTextFile('./rdd_2_coalesce') # produce un archivo"],"metadata":{"id":"jxqg0MEQZH7U","executionInfo":{"status":"ok","timestamp":1689774292249,"user_tz":180,"elapsed":1340,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# Persistencia (cache y persist)"],"metadata":{"id":"s7YEMQ1d-8lQ"}},{"cell_type":"markdown","source":["Es muy util persistir la data cuando se necesita acceder frecuentemente a la misma data, como por ejemplo cuando se esta ejecutando un algoritmo iterativo o cuando quieres realizar distintas acciones sobre un mismo linaje de transformaciones. Esto permite crear un proceso mas eficiente en cuanto a tiempo y costo de recursos.\n","\n","Hay dos maneras de persistir RDDs en Spark:\n","1. ```cache()```\n","2. ```persist()```\n","\n","Existen distintos tipos de almacenamiento para persist (que se importan de ```pyspark.StorageLevel```)\n","\n","\n","Asi mismo si se necesita vaciar el cache de un nodo manualmente entonces se usa el metodo ```unpersist()```"],"metadata":{"id":"WShQ78t4_EXU"}},{"cell_type":"code","source":["import pyspark"],"metadata":{"id":"CNibyrdcQC28","executionInfo":{"status":"ok","timestamp":1689774292250,"user_tz":180,"elapsed":13,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["[i for i in dir(pyspark.StorageLevel) if not i.startswith(\"_\")]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B57P9XzMQLaE","outputId":"a7a83059-288e-411b-b18a-11ad65c0dca4","executionInfo":{"status":"ok","timestamp":1689774292250,"user_tz":180,"elapsed":13,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['DISK_ONLY',\n"," 'DISK_ONLY_2',\n"," 'DISK_ONLY_3',\n"," 'MEMORY_AND_DISK',\n"," 'MEMORY_AND_DISK_2',\n"," 'MEMORY_AND_DISK_DESER',\n"," 'MEMORY_ONLY',\n"," 'MEMORY_ONLY_2',\n"," 'NONE',\n"," 'OFF_HEAP']"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["rdd_1 = sc.parallelize([\"hola\", \"soy\", \"charly\"])"],"metadata":{"id":"Tjnb-AxIMjXj","executionInfo":{"status":"ok","timestamp":1689774292251,"user_tz":180,"elapsed":8,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def crear_delay(x):\n","    time.sleep(5)\n","    return (x,1) # (\"hola\", 1)\n","\n","rdd_2 = rdd_1.map(lambda x: crear_delay(x))"],"metadata":{"id":"KyURmt-BMpc1","executionInfo":{"status":"ok","timestamp":1689774292252,"user_tz":180,"elapsed":9,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# este resultado tarda 15 segundos aprox porque solo tenemos un nodo (no hay realmente una mejora porque no se puede realizar de manera paralela)\n","%%time\n","rdd_2.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCEOe3-BM8pO","outputId":"138c1e22-d4bd-427b-be32-9df473b9bd8a","executionInfo":{"status":"ok","timestamp":1689774307755,"user_tz":180,"elapsed":15511,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 98.3 ms, sys: 16.1 ms, total: 114 ms\n","Wall time: 15.2 s\n"]},{"output_type":"execute_result","data":{"text/plain":["[('hola', 1), ('soy', 1), ('charly', 1)]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["rdd_2.cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6O9xygPQM_ke","outputId":"06bfaad8-bb4c-4b39-e5b7-4f016a6d38af","executionInfo":{"status":"ok","timestamp":1689774307757,"user_tz":180,"elapsed":36,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonRDD[27] at collect at <timed eval>:1"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# ya que dijimos que sea cacheada entonces el resultado de esta celda sera cacheado, para las mismas transformaciones que crean rdd_2\n","%%time\n","rdd_2.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6PHt040NJcU","outputId":"49ad9102-e745-4912-b544-da2e36587283","executionInfo":{"status":"ok","timestamp":1689774323008,"user_tz":180,"elapsed":15281,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 90.7 ms, sys: 6.39 ms, total: 97.1 ms\n","Wall time: 15.4 s\n"]},{"output_type":"execute_result","data":{"text/plain":["[('hola', 1), ('soy', 1), ('charly', 1)]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# ahora este resultado sera inmediato porque no esta realizando las transformaciones, simplemente agarra rdd_2 directamente de la memoria\n","%%time\n","rdd_2.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugt4qjI2NM_5","outputId":"c4a1d30a-f322-45bf-fefd-219ff9848e12","executionInfo":{"status":"ok","timestamp":1689774323468,"user_tz":180,"elapsed":469,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 5.65 ms, sys: 0 ns, total: 5.65 ms\n","Wall time: 172 ms\n"]},{"output_type":"execute_result","data":{"text/plain":["[('hola', 1), ('soy', 1), ('charly', 1)]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["rdd_2.is_cached"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQfpSX4sW3Tm","outputId":"1c241598-93c5-4c8e-fec4-393d68bcff26","executionInfo":{"status":"ok","timestamp":1689774323469,"user_tz":180,"elapsed":6,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# es importante realizar la limpieza de la memoria para no recibir luego un error de OutOfMemory\n","rdd_2.unpersist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G032qxy3Nb63","outputId":"7f2dd2d6-943a-40f2-a520-143115a5b9b8","executionInfo":{"status":"ok","timestamp":1689774323469,"user_tz":180,"elapsed":3,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonRDD[27] at collect at <timed eval>:1"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# ya que el unpersist() lo saca de la memoria entonces ahora vuelve a ejecutar todas las transformaciones\n","%%time\n","rdd_2.collect()"],"metadata":{"id":"SRnpePQ8Ndx0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689774338827,"user_tz":180,"elapsed":15360,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}},"outputId":"36546ac9-e194-4508-dd62-6cd9a70878c2"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 92.9 ms, sys: 10.6 ms, total: 103 ms\n","Wall time: 15.3 s\n"]},{"output_type":"execute_result","data":{"text/plain":["[('hola', 1), ('soy', 1), ('charly', 1)]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# realizando la persistencia en otro nivel\n","rdd_2.persist(pyspark.StorageLevel.DISK_ONLY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JDuYnE8NfJP","outputId":"b0311618-bce8-4c40-e640-ae0e19ea78a5","executionInfo":{"status":"ok","timestamp":1689774338827,"user_tz":180,"elapsed":13,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonRDD[27] at collect at <timed eval>:1"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["%%time\n","rdd_2.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzfuQ52ERMHh","outputId":"a451b172-adbf-4628-e6b5-8f15e8141a98","executionInfo":{"status":"ok","timestamp":1689774354108,"user_tz":180,"elapsed":15291,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 85.7 ms, sys: 14.3 ms, total: 100 ms\n","Wall time: 15.2 s\n"]},{"output_type":"execute_result","data":{"text/plain":["[('hola', 1), ('soy', 1), ('charly', 1)]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["%%time\n","rdd_2.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSqzJyQrRPLr","outputId":"4b9ae766-2759-45f7-82d8-6649855c4f44","executionInfo":{"status":"ok","timestamp":1689774354109,"user_tz":180,"elapsed":36,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 5.21 ms, sys: 1.04 ms, total: 6.25 ms\n","Wall time: 54.6 ms\n"]},{"output_type":"execute_result","data":{"text/plain":["[('hola', 1), ('soy', 1), ('charly', 1)]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["print(rdd_2.getStorageLevel())\n","rdd_2.unpersist()\n","print(rdd_2.getStorageLevel())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UP65sHbqRYlw","outputId":"7c8229ea-7742-47e5-adf8-3ae5a809630d","executionInfo":{"status":"ok","timestamp":1689774354110,"user_tz":180,"elapsed":30,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Disk Serialized 1x Replicated\n","Serialized 1x Replicated\n"]}]},{"cell_type":"code","source":["print(rdd_2.is_cached)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gAC4Atd-T354","outputId":"df8d85bc-507e-4e7d-f502-c4020ab491e0","executionInfo":{"status":"ok","timestamp":1689774354110,"user_tz":180,"elapsed":26,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"code","source":["rdd_2.cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41p9PDMLX6W1","outputId":"bd8ed1ad-02af-4022-aadb-4e3490d3c08c","executionInfo":{"status":"ok","timestamp":1689774354111,"user_tz":180,"elapsed":23,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonRDD[27] at collect at <timed eval>:1"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["print(rdd_2.getStorageLevel())\n","rdd_2.unpersist()\n","print(rdd_2.getStorageLevel())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHSg9LlPX-VP","outputId":"1f2f1bfc-2082-46d5-9686-f973c8d5b0ce","executionInfo":{"status":"ok","timestamp":1689774354114,"user_tz":180,"elapsed":22,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Memory Serialized 1x Replicated\n","Serialized 1x Replicated\n"]}]},{"cell_type":"markdown","source":["# Variables tipo Broadcast\n","Permiten usar un variable (read only) cacheada en cada nodo en lugar de enviar una copia de la variable en cada tarea. Pueden ser usada por ejemplo para darle una copia a cada nodo de un dataset grande que sea usado como input."],"metadata":{"id":"zhp9qMaZWajk"}},{"cell_type":"code","source":["bc_var = sc.broadcast([1, 2, 3, 4, 5])"],"metadata":{"id":"fCAKicpiWiaY","executionInfo":{"status":"ok","timestamp":1689774354115,"user_tz":180,"elapsed":20,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["[i for i in dir(bc_var) if not i.startswith(\"_\")]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JN6m4qNRWraQ","outputId":"6c61d347-320f-4674-e3de-6e333a6aee29","executionInfo":{"status":"ok","timestamp":1689774354116,"user_tz":180,"elapsed":21,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['destroy', 'dump', 'load', 'load_from_path', 'unpersist', 'value']"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["bc_var"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EV7kkei8YijE","outputId":"f0f664da-02d8-4c54-ec27-0c8f4ea528a9","executionInfo":{"status":"ok","timestamp":1689774354536,"user_tz":180,"elapsed":437,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.broadcast.Broadcast at 0x7e14d1a610f0>"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["bc_var.value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vv7-WLgxWz9h","outputId":"4b486e69-a952-455f-9ebb-afce0788b8d1","executionInfo":{"status":"ok","timestamp":1689774354537,"user_tz":180,"elapsed":37,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3, 4, 5]"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["bc_var.unpersist() # esto borrara las copias de los cache de cada executor"],"metadata":{"id":"mkL7kJHiW2nm","executionInfo":{"status":"ok","timestamp":1689774354538,"user_tz":180,"elapsed":15,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["lista = [1,2,3,4,5,6,7,8,9]\n","suma = 0\n","for num in lista:\n","    suma += num\n","print(suma)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgLDbarjZAnR","outputId":"0953b050-0da3-47c1-a4e0-582b884336d0","executionInfo":{"status":"ok","timestamp":1689774354538,"user_tz":180,"elapsed":14,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["45\n"]}]},{"cell_type":"code","source":["# acumuladores...\n","ac_var = sc.accumulator(0)"],"metadata":{"id":"3MnuUtJkZHKc","executionInfo":{"status":"ok","timestamp":1689774354539,"user_tz":180,"elapsed":11,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["sc.parallelize([1,2,3,4,5,6,7,8,9]).foreach(lambda x: ac_var.add(x))"],"metadata":{"id":"cAHpXBiIZMRJ","executionInfo":{"status":"ok","timestamp":1689774354539,"user_tz":180,"elapsed":11,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["ac_var.value"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_myzgcQzZX3v","outputId":"cce13f99-9f07-4995-b17e-665832f7cee6","executionInfo":{"status":"ok","timestamp":1689774354540,"user_tz":180,"elapsed":11,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["45"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["# Spark UI\n","---\n"],"metadata":{"id":"QTlw3pq4lx91"}},{"cell_type":"markdown","source":["Desde aqui podras monitorear el progreso de las tareas ejecutadas por spark, asi como visualizar los planes realizados por el master. Se puede visualizar en el nodo 4040 (por defecto) del nodo master. En nuestro caso lo mostraremos en el 4050. La interfaz es realmente util para hacer tunning y debugging.\n","\n","Normalmente si estuvieses en tu computadora podrias ver la interfaz simplemente al escribir:\n","http://localhost:4040/\n","\n","\n","En este caso ya que estamos en una instancia de Colab necesitamos usar Ngrok para enviar lo que sale del puerto 4050 a una url publica temporal."],"metadata":{"id":"i2YRAUbKmy-4"}},{"cell_type":"markdown","source":["## Usando Ngrok para visibilizar el SparkUI desde colab"],"metadata":{"id":"6DEMacOvf8Of"}},{"cell_type":"code","source":["import requests\n","with open(\"./ngrok_tunnel.py\", \"wb\") as f:\n","    f.write(requests.get(\"https://raw.githubusercontent.com/engcarlosperezmolero/resources_and_tools/main/tools/ngrok_tunnel.py\").content)"],"metadata":{"id":"Q2bx9SSAbIXF","executionInfo":{"status":"ok","timestamp":1689774354831,"user_tz":180,"elapsed":299,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["from ngrok_tunnel import NgrokTunnel"],"metadata":{"id":"bTaKrKjyezRv","executionInfo":{"status":"ok","timestamp":1689774354832,"user_tz":180,"elapsed":7,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["ngrok = NgrokTunnel('2SnEdNgWGVppdDd5wUjVjYKCPgN_24kR77UZQ2yhgQmbhh5x4', 'linux') # se recomienda cambiar la TOKEN de NGROK api (crear cuenta)\n","ngrok.download_and_unzip('https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz')\n","ngrok.run_ngrok(4050)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7IOl2Bjme0BO","outputId":"014d1eff-96de-4e12-c8c4-371882ef3f6a","executionInfo":{"status":"ok","timestamp":1689774376078,"user_tz":180,"elapsed":629,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Download complete and extraction complete!\n"]}]},{"cell_type":"code","source":["ngrok.get_public_url()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJbQdV8se1mR","outputId":"c042c960-f2ab-4969-f64c-e55ce8e4eb93","executionInfo":{"status":"ok","timestamp":1689774378586,"user_tz":180,"elapsed":265,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Public url: https://6e3c-35-231-84-107.ngrok-free.app\n"]}]},{"cell_type":"markdown","source":["# Leyendo un archivo usando un RDD\n","---"],"metadata":{"id":"rklnQ70ngGwP"}},{"cell_type":"code","source":["%%writefile test.txt\n","Hola que tal soy charly de humai\n","Que tal charly soy Spark\n","Pero a mi me gusta Python\n","Genial puedes usar pyspark para comunicarte con Spark\n","Usando solo Python\n","Asi es usando solo Python\n","Genial"],"metadata":{"id":"80UtN052xHaY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689774394325,"user_tz":180,"elapsed":262,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}},"outputId":"bab431e5-2204-4f3e-83b9-c8d8b0fa7c17"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing test.txt\n"]}]},{"cell_type":"markdown","source":["## Usando SparkSession directamente"],"metadata":{"id":"DsAocF7UrU9z"}},{"cell_type":"code","source":["lines_rdd_session = spark.read.text('test.txt').rdd.map(lambda r: r[0]) # RDD[string]"],"metadata":{"id":"UKyloXMrrZ0U","executionInfo":{"status":"ok","timestamp":1689774436701,"user_tz":180,"elapsed":307,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["lines_rdd_session.collect()"],"metadata":{"id":"N1fvVzUjrte8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689774437601,"user_tz":180,"elapsed":571,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}},"outputId":"6e4dec21-6450-4a90-ed04-ffc3f557fe1a"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hola que tal soy charly de humai',\n"," 'Que tal charly soy Spark',\n"," 'Pero a mi me gusta Python',\n"," 'Genial puedes usar pyspark para comunicarte con Spark',\n"," 'Usando solo Python',\n"," 'Asi es usando solo Python',\n"," 'Genial']"]},"metadata":{},"execution_count":69}]},{"cell_type":"markdown","source":["## Usando SparkContext"],"metadata":{"id":"GhDBezDJrywP"}},{"cell_type":"code","source":["lines_rdd_context = sc.textFile('test.txt')"],"metadata":{"id":"ZvyiL3IL15_4","executionInfo":{"status":"ok","timestamp":1689774402491,"user_tz":180,"elapsed":2,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["lines_rdd_context.collect()"],"metadata":{"id":"mDE3t2qEgQDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689774402785,"user_tz":180,"elapsed":296,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}},"outputId":"6b151301-2af6-4d4e-8745-f1a60c15c178"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hola que tal soy charly de humai',\n"," 'Que tal charly soy Spark',\n"," 'Pero a mi me gusta Python',\n"," 'Genial puedes usar pyspark para comunicarte con Spark',\n"," 'Usando solo Python',\n"," 'Asi es usando solo Python',\n"," 'Genial']"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["## Realizando algunas transformaciones"],"metadata":{"id":"oyC95w0xr_ty"}},{"cell_type":"code","source":["words = lines_rdd_context.flatMap(lambda s: s.split(' ')) # 1 a varios, primero aplica la funcion a cada elemento y luego \"aplana\" el resultado"],"metadata":{"id":"-lESLfpQ7dk1","executionInfo":{"status":"ok","timestamp":1689774402786,"user_tz":180,"elapsed":3,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["words_tuple = words.map(lambda word: (word, 1))"],"metadata":{"id":"bVfk78v7sHNk","executionInfo":{"status":"ok","timestamp":1689774402786,"user_tz":180,"elapsed":3,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["words_count = words_tuple.reduceByKey(lambda x, y: x + y)"],"metadata":{"id":"IUYLsaz7znar","executionInfo":{"status":"ok","timestamp":1689774402786,"user_tz":180,"elapsed":2,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["words_count.collectAsMap()"],"metadata":{"id":"2Q0o6JxTsHVX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689774403345,"user_tz":180,"elapsed":561,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}},"outputId":"887976f0-fb27-45b8-bc96-b7de6dccf65f"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Hola': 1,\n"," 'que': 1,\n"," 'tal': 2,\n"," 'soy': 2,\n"," 'charly': 2,\n"," 'de': 1,\n"," 'humai': 1,\n"," 'Que': 1,\n"," 'Spark': 2,\n"," 'Pero': 1,\n"," 'a': 1,\n"," 'mi': 1,\n"," 'me': 1,\n"," 'gusta': 1,\n"," 'Python': 3,\n"," 'Genial': 2,\n"," 'puedes': 1,\n"," 'usar': 1,\n"," 'pyspark': 1,\n"," 'para': 1,\n"," 'comunicarte': 1,\n"," 'con': 1,\n"," 'Usando': 1,\n"," 'solo': 2,\n"," 'Asi': 1,\n"," 'es': 1,\n"," 'usando': 1}"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":[],"metadata":{"id":"kzEIIhoisHcP","executionInfo":{"status":"ok","timestamp":1689774403345,"user_tz":180,"elapsed":3,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["# Si la instalación normal llega a fallar\n","---"],"metadata":{"id":"Lo5bA5dMRUte"}},{"cell_type":"code","source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null"],"metadata":{"id":"rrR2-ndLRY4z","executionInfo":{"status":"ok","timestamp":1689774421526,"user_tz":180,"elapsed":18183,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["# si falla el wget buscar en la proxima pagina cual es el link que esta funcionando\n","# https://spark.apache.org/downloads.html\n","!wget -q https://dlcdn.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n","!tar xf spark-3.3.0-bin-hadoop3.tgz # cambiar el nombren segun el nombre correcto del archivo"],"metadata":{"id":"f7RsqPauRdRJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689774421958,"user_tz":180,"elapsed":434,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}},"outputId":"986b88b2-4864-426b-e887-2d3bd275db41"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["tar: spark-3.3.0-bin-hadoop3.tgz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\" # cambiar el nombre segun el nombre correcto del archivo"],"metadata":{"id":"dcdEOtcARdy3","executionInfo":{"status":"ok","timestamp":1689774421959,"user_tz":180,"elapsed":5,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["!pip install -q findspark"],"metadata":{"id":"w5GCl-KkReEU","executionInfo":{"status":"ok","timestamp":1689774427967,"user_tz":180,"elapsed":6012,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["import findspark # https://github.com/minrk/findspark\n","findspark.init()"],"metadata":{"id":"EU1h3JrrReL9","executionInfo":{"status":"ok","timestamp":1689774427967,"user_tz":180,"elapsed":5,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["import pyspark"],"metadata":{"id":"dFXPq0e3gSIS","executionInfo":{"status":"ok","timestamp":1689774427967,"user_tz":180,"elapsed":4,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vv4uuMgVgVGE","executionInfo":{"status":"ok","timestamp":1689774427967,"user_tz":180,"elapsed":4,"user":{"displayName":"Facundo Villena","userId":"08952518993841092128"}}},"execution_count":67,"outputs":[]}]}