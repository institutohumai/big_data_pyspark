{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK3_fvXVgjB5"
      },
      "source": [
        "# PMML\n",
        "\n",
        "El objetivo del ejercicio es tomar el codigo anterior y modificarlo para que el resultado de la API sea más útil. Es decir, no solamente cambiar el resultado numérico a clases nuevamente, sino también la fuente para poder pasarle la data sin normalizar (como viene en el dataset).\n",
        "\n",
        "No hay una única manera de hacer esto. Dependiendo de la comodidad y práctica del desarrollador puede hacerse que el archivo PMML haga el cambio, o puede hacerse desde Spark mismo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT0h2lxAgiev"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark==3.2.0 pyspark2pmml openscoring==0.5.0\n",
        "!wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
        "!wget https://repo1.maven.org/maven2/org/jpmml/pmml-sparkml/2.2.0/pmml-sparkml-2.2.0.jar\n",
        "!wget https://github.com/jpmml/jpmml-sparkml/releases/download/2.2.0/pmml-sparkml-example-executable-2.2.0.jar\n",
        "!cp *.jar /usr/local/lib/python3.7/dist-packages/pyspark/jars\n",
        "!wget https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hixfwphmiyUX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openscoring import Openscoring\n",
        "from pyspark2pmml import PMMLBuilder\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.types import StructType, DoubleType, StringType\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col, udf, rand\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import (\n",
        "    MinMaxScaler,\n",
        "    VectorAssembler,\n",
        "    OneHotEncoder,\n",
        "    StringIndexer,\n",
        "    IndexToString,\n",
        "    StringIndexerModel,\n",
        "    MinMaxScalerModel,\n",
        "    SQLTransformer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1stM2jzAgjqq"
      },
      "outputs": [],
      "source": [
        "jars = [\n",
        "  'pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  'pmml-sparkml-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-2.2.0.jar'\n",
        "]\n",
        "\n",
        "joined_jars = \",\".join(jars)\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
        "  '--packages org.jpmml:pmml-sparkml:2.0.0 ' + \\\n",
        "  f'--master local[*] --jars {joined_jars} ' + \\\n",
        "  'pyspark-shell'\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.jars', joined_jars) \\\n",
        "    .appName(\"PMML, PFA y MLeap\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxMtCwi6jHwt"
      },
      "outputs": [],
      "source": [
        "#Solucion"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}