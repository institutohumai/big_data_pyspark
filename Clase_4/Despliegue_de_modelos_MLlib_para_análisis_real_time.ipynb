{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK3_fvXVgjB5"
      },
      "source": [
        "# PMML - Predictive Model Markup Language\n",
        "\n",
        "## Motivación\n",
        "\n",
        "Como se vió en la clase anterior *Machine Learning Distribuido con PySpark*, hoy en día no hay una sola framework *probada en batalla* para machine learning en tiempo real, es decir baja latencia y alta cantidad de mensajes por unidad de tiempo.\n",
        "\n",
        "Dicho esto, lo mejor que podemos hacer es construir la solución con los componentes que tenemos disponibles.\n",
        "\n",
        "En esta clase veremos algunas maneras diferentes de mitigar este problema y poder **servir modelos en tiempo real y batch** con Spark con baja latencia y alta cantidad de mensajes por unidad de tiempo.\n",
        "\n",
        "## PMML\n",
        "\n",
        "<center>\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/en/8/80/PMML_Logo.png\" alt=\"PMML Logo\" width=\"800\"/>\n",
        "</center>\n",
        "\n",
        "**PMML** o *Predictive Model Markup Language* por sus siglas en inglés es un archivo de definición para modelos predictivos en formato XML. El objetivo es la estandarización en formato e intercambio de modelos predictivos. Este estandar define una manera para que las aplicaciones analíticas puedan describir los modelos producidos por machine learning.\n",
        "\n",
        "### Archivo PMML\n",
        "\n",
        "Más alla de que el archivo no esta pensado para que sea leido por humanos, sino para el intercambio entre frameworks y máquinas, entender las diferentes partes del archivo nos puede ayudar a comprender como funciona su intercambio.\n",
        "\n",
        "*NOTA: Se escriben los nombres en inglés ya que así se encontrarán en el archivo*\n",
        "\n",
        "- **Header o Cabecera**: Contiene información general del documento PMML como el copyright, descripción, tiempo de generación, etc.\n",
        "- **Data Dictionary o Diccionario de Datos**: Contiene definiciones para todas las variables utilizadas por el modelo\n",
        "- **Data Transformations o Transformaciones de Datos**: Permite la transformación de data original al input deseable para el modelo\n",
        "  - Normalización: mapear valores a numeros (continuos o discretos)\n",
        "  - Discretización: mapear valores continuos a discretos\n",
        "  - Mapeo de Valores: mapear valores discretos a discretos\n",
        "  - Funciones: (custom o integradas) derivar un valor como resultado de una función.\n",
        "  - Agregaciones: resumir o recolectar grupos de valores.\n",
        "- **Model o Modelo**: Contiene información sobre el modelo como nombre, funcion, algoritmo, funcion de activación y numero de capas.\n",
        "- **Mining Schema**: Una lista de todas las variables utilizadas en el modelo. Puede ser un subset del **Diccionario de Datos** pero este contiene información más detallada.\n",
        "- **Targets**: Procesado posterior al resultado del modelo, como pasar de un resultado numérico a una clasificación.\n",
        "- **Output**: Este elemento puede ser utilizado para nombrar todos los outputs esperados del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark"
      ],
      "metadata": {
        "id": "jCjnGk9-5idU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynyDZlkUg5Sv"
      },
      "source": [
        "### Dependencias\n",
        "\n",
        "Aquí se instalan las dependencias y descargan los archivos necesarios para correr este colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT0h2lxAgiev",
        "outputId": "ebc58045-5ae6-4c11-8519-a3aaf4d01957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.2.0\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyspark2pmml\n",
            "  Downloading pyspark2pmml-0.5.1.tar.gz (1.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openscoring==0.5.0\n",
            "  Downloading openscoring-0.5.0.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.2 (from pyspark==3.2.0)\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openscoring==0.5.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from openscoring==0.5.0) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->openscoring==0.5.0) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openscoring==0.5.0) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openscoring==0.5.0) (1.16.0)\n",
            "Building wheels for collected packages: pyspark, openscoring, pyspark2pmml\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805897 sha256=3bf1228ef0b82e2afe42d2418d9176a2d2caa86fc1bb206d873dccf86673b94e\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/97/d3/8b6d964c8700e4fbb561c71638a92ec55dac9be51eb5fea86d\n",
            "  Building wheel for openscoring (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openscoring: filename=openscoring-0.5.0-py3-none-any.whl size=15447 sha256=828074967167a843980799e0c3c1d0d26e4ae32459600c4aa24e540313985fca\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/dc/6d/f693595af7fc650ef112694173f372d1e9dcc692311cd9d6c1\n",
            "  Building wheel for pyspark2pmml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark2pmml: filename=pyspark2pmml-0.5.1-py3-none-any.whl size=2397 sha256=fb353c8c4f7b6cb1688b96ea01ed402914e44ebfe87b7696aa172ed788be8772\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/45/ab/d2410fea687cbc535f27d7ad887c47051997445f27ca7c4b74\n",
            "Successfully built pyspark openscoring pyspark2pmml\n",
            "Installing collected packages: py4j, pyspark2pmml, pyspark, openscoring\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed openscoring-0.5.0 py4j-0.10.9.2 pyspark-3.2.0 pyspark2pmml-0.5.1\n",
            "--2023-08-07 22:52:05--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975 (3.9K) [text/plain]\n",
            "Saving to: ‘iris.csv’\n",
            "\n",
            "iris.csv            100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-07 22:52:05 (76.2 MB/s) - ‘iris.csv’ saved [3975/3975]\n",
            "\n",
            "--2023-08-07 22:52:05--  https://repo1.maven.org/maven2/org/jpmml/pmml-sparkml/2.2.0/pmml-sparkml-2.2.0.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173873 (170K) [application/java-archive]\n",
            "Saving to: ‘pmml-sparkml-2.2.0.jar’\n",
            "\n",
            "pmml-sparkml-2.2.0. 100%[===================>] 169.80K   588KB/s    in 0.3s    \n",
            "\n",
            "2023-08-07 22:52:06 (588 KB/s) - ‘pmml-sparkml-2.2.0.jar’ saved [173873/173873]\n",
            "\n",
            "--2023-08-07 22:52:06--  https://github.com/jpmml/jpmml-sparkml/releases/download/2.2.0/pmml-sparkml-example-executable-2.2.0.jar\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/58119316/7d46db4f-6687-42a6-bf76-39dd3b4e77ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T225206Z&X-Amz-Expires=300&X-Amz-Signature=3d71a380a6dc85a160f5aeab0676fd36ae1273f5d2a015beb94f03a3ffb83c4e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58119316&response-content-disposition=attachment%3B%20filename%3Dpmml-sparkml-example-executable-2.2.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-08-07 22:52:07--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/58119316/7d46db4f-6687-42a6-bf76-39dd3b4e77ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T225206Z&X-Amz-Expires=300&X-Amz-Signature=3d71a380a6dc85a160f5aeab0676fd36ae1273f5d2a015beb94f03a3ffb83c4e&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=58119316&response-content-disposition=attachment%3B%20filename%3Dpmml-sparkml-example-executable-2.2.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5885135 (5.6M) [application/octet-stream]\n",
            "Saving to: ‘pmml-sparkml-example-executable-2.2.0.jar’\n",
            "\n",
            "pmml-sparkml-exampl 100%[===================>]   5.61M  25.8MB/s    in 0.2s    \n",
            "\n",
            "2023-08-07 22:52:07 (25.8 MB/s) - ‘pmml-sparkml-example-executable-2.2.0.jar’ saved [5885135/5885135]\n",
            "\n",
            "cp: target '/usr/local/lib/python3.7/dist-packages/pyspark/jars' is not a directory\n",
            "--2023-08-07 22:52:07--  https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T225208Z&X-Amz-Expires=300&X-Amz-Signature=156b430f3e9a10efe4e2703f25b83268c143df7736f1c9b536ab6222c3e45068&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-08-07 22:52:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/9178484/e5dac4d7-9d82-4026-9aad-b7148765e61e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230807T225208Z&X-Amz-Expires=300&X-Amz-Signature=156b430f3e9a10efe4e2703f25b83268c143df7736f1c9b536ab6222c3e45068&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=9178484&response-content-disposition=attachment%3B%20filename%3Dopenscoring-server-executable-2.1.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25110251 (24M) [application/octet-stream]\n",
            "Saving to: ‘openscoring-server-executable-2.1.0.jar’\n",
            "\n",
            "openscoring-server- 100%[===================>]  23.95M  19.5MB/s    in 1.2s    \n",
            "\n",
            "2023-08-07 22:52:10 (19.5 MB/s) - ‘openscoring-server-executable-2.1.0.jar’ saved [25110251/25110251]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.2.0 pyspark2pmml openscoring==0.5.0\n",
        "!wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
        "!wget https://repo1.maven.org/maven2/org/jpmml/pmml-sparkml/2.2.0/pmml-sparkml-2.2.0.jar\n",
        "!wget https://github.com/jpmml/jpmml-sparkml/releases/download/2.2.0/pmml-sparkml-example-executable-2.2.0.jar\n",
        "!cp *.jar /usr/local/lib/python3.7/dist-packages/pyspark/jars\n",
        "!wget https://github.com/openscoring/openscoring/releases/download/2.1.0/openscoring-server-executable-2.1.0.jar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Ay41MvixBu"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hixfwphmiyUX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openscoring import Openscoring\n",
        "\n",
        "from pyspark2pmml import PMMLBuilder\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.sql.types import StructType, DoubleType, StringType\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import (\n",
        "    MinMaxScaler,\n",
        "    VectorAssembler,\n",
        "    OneHotEncoder,\n",
        "    StringIndexer,\n",
        "    IndexToString\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creando el cluster de Spark con las dependencias instaladas\n",
        "\n",
        "Como se ve aquí, se estan agregando archivos JAR. Los JAR son paquetes de codigo compilado de Java. Para poder agregar dependencias de Java a Spark, es necesario descargar este tipo de archivos y agregarlos al cluster. Hay muchas maneras de hacer esto. En este caso lo que se esta haciendo es agregarlos como configuración.\n",
        "\n",
        "Adicionalmente, se crea el cluster de Spark con `local[*]` para que el cluster decida la cantidad de threads que necesita para correr el notebook."
      ],
      "metadata": {
        "id": "owopwYT02Hk9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1stM2jzAgjqq"
      },
      "outputs": [],
      "source": [
        "jars = [\n",
        "  'pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  'pmml-sparkml-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-example-executable-2.2.0.jar',\n",
        "  '/content/pmml-sparkml-2.2.0.jar'\n",
        "]\n",
        "\n",
        "joined_jars = \",\".join(jars)\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
        "  '--packages org.jpmml:pmml-sparkml:2.0.0 ' + \\\n",
        "  f'--master local[*] --jars {joined_jars} ' + \\\n",
        "  'pyspark-shell'\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.jars', joined_jars) \\\n",
        "    .appName(\"PMML\") \\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando el dataset\n",
        "\n",
        "En el siguiente bloque se define el schema. En la mayoría de los casos esto no es necesario, pero como las columnas del dataset `iris.csv` tienen puntos en los nombres: `sepal.width` Spark entiende que es un `Struct` o un objeto y trata de descomponerlo. Como no puede, este falla. Lo que hacemos para solucionar esto es cambiarle el nombre agregando *backticks* (el siguiente caracter: `)"
      ],
      "metadata": {
        "id": "5gVrUFGP21wO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxMtCwi6jHwt",
        "outputId": "067fc7d0-4ffc-4bab-918f-e363a02be7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------+------------+-------+\n",
            "|sepal_width|sepal_length|petal_width|petal_length|variety|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "|        3.5|         5.1|        0.2|         1.4| Setosa|\n",
            "|        3.0|         4.9|        0.2|         1.4| Setosa|\n",
            "|        3.2|         4.7|        0.2|         1.3| Setosa|\n",
            "|        3.1|         4.6|        0.2|         1.5| Setosa|\n",
            "|        3.6|         5.0|        0.2|         1.4| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.7| Setosa|\n",
            "|        3.4|         4.6|        0.3|         1.4| Setosa|\n",
            "|        3.4|         5.0|        0.2|         1.5| Setosa|\n",
            "|        2.9|         4.4|        0.2|         1.4| Setosa|\n",
            "|        3.1|         4.9|        0.1|         1.5| Setosa|\n",
            "|        3.7|         5.4|        0.2|         1.5| Setosa|\n",
            "|        3.4|         4.8|        0.2|         1.6| Setosa|\n",
            "|        3.0|         4.8|        0.1|         1.4| Setosa|\n",
            "|        3.0|         4.3|        0.1|         1.1| Setosa|\n",
            "|        4.0|         5.8|        0.2|         1.2| Setosa|\n",
            "|        4.4|         5.7|        0.4|         1.5| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.3| Setosa|\n",
            "|        3.5|         5.1|        0.3|         1.4| Setosa|\n",
            "|        3.8|         5.7|        0.3|         1.7| Setosa|\n",
            "|        3.8|         5.1|        0.3|         1.5| Setosa|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- sepal_width: double (nullable = true)\n",
            " |-- sepal_length: double (nullable = true)\n",
            " |-- petal_width: double (nullable = true)\n",
            " |-- petal_length: double (nullable = true)\n",
            " |-- variety: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "iris_schema = StructType().add('sepal.length', DoubleType()) \\\n",
        "  .add('sepal.width', DoubleType()) \\\n",
        "  .add('petal.length', DoubleType()) \\\n",
        "  .add('petal.width', DoubleType()) \\\n",
        "  .add('variety', StringType())\n",
        "\n",
        "# renaming columns to remove dot for better compatibility\n",
        "iris_df = spark.read.format('csv') \\\n",
        "  .schema(iris_schema) \\\n",
        "  .option('header', 'true') \\\n",
        "  .load('iris.csv') \\\n",
        "  .select(\n",
        "      col('`sepal.width`').alias('sepal_width'),\n",
        "      col('`sepal.length`').alias('sepal_length'),\n",
        "      col('`petal.width`').alias('petal_width'),\n",
        "      col('`petal.length`').alias('petal_length'),\n",
        "      col('variety')\n",
        "    )\n",
        "iris_df.show()\n",
        "iris_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocesamiento de los datos para el modelo\n",
        "\n",
        "El siguiente bloque puede considerarse que ejecuta acciones redundantes, pero fue escrito asi intencionalmente para mostrar que puede seguir modificandose el `DataFrame` original y no necesariamente tiene que ser todo trabajado dentro de un vector proveniente del `VectorAssembler`"
      ],
      "metadata": {
        "id": "K1hwaZoG3WLi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EouPqvUphPE3",
        "outputId": "2044fb0f-1287-4f99-aee9-50e2578e712f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------+------------+-------+\n",
            "|sepal_width|sepal_length|petal_width|petal_length|variety|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "|        3.5|         5.1|        0.2|         1.4| Setosa|\n",
            "|        3.0|         4.9|        0.2|         1.4| Setosa|\n",
            "|        3.2|         4.7|        0.2|         1.3| Setosa|\n",
            "|        3.1|         4.6|        0.2|         1.5| Setosa|\n",
            "|        3.6|         5.0|        0.2|         1.4| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.7| Setosa|\n",
            "|        3.4|         4.6|        0.3|         1.4| Setosa|\n",
            "|        3.4|         5.0|        0.2|         1.5| Setosa|\n",
            "|        2.9|         4.4|        0.2|         1.4| Setosa|\n",
            "|        3.1|         4.9|        0.1|         1.5| Setosa|\n",
            "|        3.7|         5.4|        0.2|         1.5| Setosa|\n",
            "|        3.4|         4.8|        0.2|         1.6| Setosa|\n",
            "|        3.0|         4.8|        0.1|         1.4| Setosa|\n",
            "|        3.0|         4.3|        0.1|         1.1| Setosa|\n",
            "|        4.0|         5.8|        0.2|         1.2| Setosa|\n",
            "|        4.4|         5.7|        0.4|         1.5| Setosa|\n",
            "|        3.9|         5.4|        0.4|         1.3| Setosa|\n",
            "|        3.5|         5.1|        0.3|         1.4| Setosa|\n",
            "|        3.8|         5.7|        0.3|         1.7| Setosa|\n",
            "|        3.8|         5.1|        0.3|         1.5| Setosa|\n",
            "+-----------+------------+-----------+------------+-------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+\n",
            "|sepal_width|sepal_length|petal_width|petal_length|variety|sepal_length_scaled|sepal_width_scaled|petal_length_scaled|petal_width_scaled|\n",
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+\n",
            "|        3.5|         5.1|        0.2|         1.4| Setosa|              0.222|             0.625|              0.068|             0.042|\n",
            "|        3.0|         4.9|        0.2|         1.4| Setosa|              0.167|             0.417|              0.068|             0.042|\n",
            "|        3.2|         4.7|        0.2|         1.3| Setosa|              0.111|               0.5|              0.051|             0.042|\n",
            "|        3.1|         4.6|        0.2|         1.5| Setosa|              0.083|             0.458|              0.085|             0.042|\n",
            "|        3.6|         5.0|        0.2|         1.4| Setosa|              0.194|             0.667|              0.068|             0.042|\n",
            "|        3.9|         5.4|        0.4|         1.7| Setosa|              0.306|             0.792|              0.119|             0.125|\n",
            "|        3.4|         4.6|        0.3|         1.4| Setosa|              0.083|             0.583|              0.068|             0.083|\n",
            "|        3.4|         5.0|        0.2|         1.5| Setosa|              0.194|             0.583|              0.085|             0.042|\n",
            "|        2.9|         4.4|        0.2|         1.4| Setosa|              0.028|             0.375|              0.068|             0.042|\n",
            "|        3.1|         4.9|        0.1|         1.5| Setosa|              0.167|             0.458|              0.085|               0.0|\n",
            "|        3.7|         5.4|        0.2|         1.5| Setosa|              0.306|             0.708|              0.085|             0.042|\n",
            "|        3.4|         4.8|        0.2|         1.6| Setosa|              0.139|             0.583|              0.102|             0.042|\n",
            "|        3.0|         4.8|        0.1|         1.4| Setosa|              0.139|             0.417|              0.068|               0.0|\n",
            "|        3.0|         4.3|        0.1|         1.1| Setosa|                0.0|             0.417|              0.017|               0.0|\n",
            "|        4.0|         5.8|        0.2|         1.2| Setosa|              0.417|             0.833|              0.034|             0.042|\n",
            "|        4.4|         5.7|        0.4|         1.5| Setosa|              0.389|               1.0|              0.085|             0.125|\n",
            "|        3.9|         5.4|        0.4|         1.3| Setosa|              0.306|             0.792|              0.051|             0.125|\n",
            "|        3.5|         5.1|        0.3|         1.4| Setosa|              0.222|             0.625|              0.068|             0.083|\n",
            "|        3.8|         5.7|        0.3|         1.7| Setosa|              0.389|              0.75|              0.119|             0.083|\n",
            "|        3.8|         5.1|        0.3|         1.5| Setosa|              0.222|              0.75|              0.085|             0.083|\n",
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "labels = ['variety']\n",
        "\n",
        "iris_df.show()\n",
        "\n",
        "df = iris_df\n",
        "\n",
        "# UDF for converting column type from vector to double type\n",
        "unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n",
        "\n",
        "for feature in features:\n",
        "  # VectorAssembler Transformation - Converting column to vector type\n",
        "  vector_feature = f'{feature}_vect'\n",
        "  assembler = VectorAssembler(inputCols=[feature], outputCol=vector_feature)\n",
        "\n",
        "  # MinMaxScaler Transformation\n",
        "  scaled_feature = f'{feature}_scaled'\n",
        "  scaler = MinMaxScaler(inputCol=vector_feature, outputCol=scaled_feature)\n",
        "\n",
        "  # Pipeline of VectorAssembler and MinMaxScaler\n",
        "  pipeline = Pipeline(stages=[assembler, scaler])\n",
        "\n",
        "  # Fitting pipeline on dataframe\n",
        "  df = pipeline.fit(df) \\\n",
        "    .transform(df) \\\n",
        "    .withColumn(scaled_feature, unlist(scaled_feature)) \\\n",
        "    .drop(vector_feature)\n",
        "\n",
        "df.show()\n",
        "iris_df_scaled = df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el próximo paso, se define el `StringIndexer` para mapear valores categoricos a numéricos"
      ],
      "metadata": {
        "id": "nUuCz0Nv3l8u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvZeeru80nsZ",
        "outputId": "f826ef6f-7ab6-44f8-c5b0-24cb4eb287c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+---------------+\n",
            "|sepal_width|sepal_length|petal_width|petal_length|variety|sepal_length_scaled|sepal_width_scaled|petal_length_scaled|petal_width_scaled|variety_numeric|\n",
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+---------------+\n",
            "|        3.5|         5.1|        0.2|         1.4| Setosa|              0.222|             0.625|              0.068|             0.042|            0.0|\n",
            "|        3.0|         4.9|        0.2|         1.4| Setosa|              0.167|             0.417|              0.068|             0.042|            0.0|\n",
            "|        3.2|         4.7|        0.2|         1.3| Setosa|              0.111|               0.5|              0.051|             0.042|            0.0|\n",
            "|        3.1|         4.6|        0.2|         1.5| Setosa|              0.083|             0.458|              0.085|             0.042|            0.0|\n",
            "|        3.6|         5.0|        0.2|         1.4| Setosa|              0.194|             0.667|              0.068|             0.042|            0.0|\n",
            "|        3.9|         5.4|        0.4|         1.7| Setosa|              0.306|             0.792|              0.119|             0.125|            0.0|\n",
            "|        3.4|         4.6|        0.3|         1.4| Setosa|              0.083|             0.583|              0.068|             0.083|            0.0|\n",
            "|        3.4|         5.0|        0.2|         1.5| Setosa|              0.194|             0.583|              0.085|             0.042|            0.0|\n",
            "|        2.9|         4.4|        0.2|         1.4| Setosa|              0.028|             0.375|              0.068|             0.042|            0.0|\n",
            "|        3.1|         4.9|        0.1|         1.5| Setosa|              0.167|             0.458|              0.085|               0.0|            0.0|\n",
            "|        3.7|         5.4|        0.2|         1.5| Setosa|              0.306|             0.708|              0.085|             0.042|            0.0|\n",
            "|        3.4|         4.8|        0.2|         1.6| Setosa|              0.139|             0.583|              0.102|             0.042|            0.0|\n",
            "|        3.0|         4.8|        0.1|         1.4| Setosa|              0.139|             0.417|              0.068|               0.0|            0.0|\n",
            "|        3.0|         4.3|        0.1|         1.1| Setosa|                0.0|             0.417|              0.017|               0.0|            0.0|\n",
            "|        4.0|         5.8|        0.2|         1.2| Setosa|              0.417|             0.833|              0.034|             0.042|            0.0|\n",
            "|        4.4|         5.7|        0.4|         1.5| Setosa|              0.389|               1.0|              0.085|             0.125|            0.0|\n",
            "|        3.9|         5.4|        0.4|         1.3| Setosa|              0.306|             0.792|              0.051|             0.125|            0.0|\n",
            "|        3.5|         5.1|        0.3|         1.4| Setosa|              0.222|             0.625|              0.068|             0.083|            0.0|\n",
            "|        3.8|         5.7|        0.3|         1.7| Setosa|              0.389|              0.75|              0.119|             0.083|            0.0|\n",
            "|        3.8|         5.1|        0.3|         1.5| Setosa|              0.222|              0.75|              0.085|             0.083|            0.0|\n",
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "indexers = [StringIndexer(inputCol=label, outputCol=f'{label}_numeric') \\\n",
        "            .fit(iris_df_scaled) for label in labels]\n",
        "\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "df_indexed = pipeline.fit(iris_df_scaled).transform(iris_df_scaled)\n",
        "df_indexed.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training y testing set (y validation cuando es posible)\n",
        "\n",
        "Finalmente, se divide en el test de training y testing.\n",
        "\n",
        "Recuerden que cuando peudan siempre deberan agregar el test de validación para evitar *overfittear* al set de testing."
      ],
      "metadata": {
        "id": "matdvExR3vUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i01kzUEr3y3a",
        "outputId": "882dfb2a-0ff1-4ac8-87b9-89b0958bc78c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+---------------+\n",
            "|sepal_width|sepal_length|petal_width|petal_length|variety|sepal_length_scaled|sepal_width_scaled|petal_length_scaled|petal_width_scaled|variety_numeric|\n",
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+---------------+\n",
            "|        3.5|         5.1|        0.2|         1.4| Setosa|              0.222|             0.625|              0.068|             0.042|            0.0|\n",
            "|        3.0|         4.9|        0.2|         1.4| Setosa|              0.167|             0.417|              0.068|             0.042|            0.0|\n",
            "|        3.2|         4.7|        0.2|         1.3| Setosa|              0.111|               0.5|              0.051|             0.042|            0.0|\n",
            "|        3.1|         4.6|        0.2|         1.5| Setosa|              0.083|             0.458|              0.085|             0.042|            0.0|\n",
            "|        3.6|         5.0|        0.2|         1.4| Setosa|              0.194|             0.667|              0.068|             0.042|            0.0|\n",
            "+-----------+------------+-----------+------------+-------+-------------------+------------------+-------------------+------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------------------+------------------+-------------------+------------------+-----+\n",
            "|sepal_length_scaled|sepal_width_scaled|petal_length_scaled|petal_width_scaled|label|\n",
            "+-------------------+------------------+-------------------+------------------+-----+\n",
            "|                0.0|             0.417|              0.017|               0.0|  0.0|\n",
            "|              0.028|             0.417|              0.051|             0.042|  0.0|\n",
            "|              0.028|               0.5|              0.051|             0.042|  0.0|\n",
            "|              0.056|             0.125|              0.051|             0.083|  0.0|\n",
            "|              0.083|             0.458|              0.085|             0.042|  0.0|\n",
            "+-------------------+------------------+-------------------+------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------------------+------------------+-------------------+------------------+-----+\n",
            "|sepal_length_scaled|sepal_width_scaled|petal_length_scaled|petal_width_scaled|label|\n",
            "+-------------------+------------------+-------------------+------------------+-----+\n",
            "|              0.028|             0.375|              0.068|             0.042|  0.0|\n",
            "|              0.111|               0.5|              0.051|             0.042|  0.0|\n",
            "|              0.139|             0.417|              0.068|             0.083|  0.0|\n",
            "|              0.167|             0.208|              0.593|             0.667|  2.0|\n",
            "|              0.194|               0.0|              0.424|             0.375|  1.0|\n",
            "+-------------------+------------------+-------------------+------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(training, testing) = df_indexed.select('sepal_length_scaled',\n",
        "                                        'sepal_width_scaled',\n",
        "                                        'petal_length_scaled',\n",
        "                                        'petal_width_scaled',\n",
        "                                        'variety_numeric') \\\n",
        "                                        .withColumn('label',\n",
        "                                                    col('variety_numeric')) \\\n",
        "                                        .drop('variety_numeric') \\\n",
        "                                        .randomSplit([0.7, 0.3])\n",
        "\n",
        "df_indexed.show(5)\n",
        "training.show(5)\n",
        "testing.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "En el siguiente paso se crea el modelo. Si se fijan, también estamos creando un `IndexToString` que ejecuta el proceso inverso del `StringIndexer`. Cuando tengo el resultado del modelo nunca voy a saber si `0` corresponde a `Setosa` o `Virginica`. Para esto sirve el `IndexToString`.\n",
        "\n",
        "Estamos tomando un `RandomForestClassifier` que es uno de los algoritmos más robustos dentro del machine learning tabular."
      ],
      "metadata": {
        "id": "Xt7q0BzP3-_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTw9vbvwhZxw",
        "outputId": "4fc05aa8-0238-414c-fcc2-dc79031d449a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 1.0\n",
            "Train Error: 0.0\n",
            "Test Accuracy: 0.9615384615384616\n",
            "Test Error: 0.038461538461538436\n",
            "+-------------------+------------------+-------------------+------------------+-----+--------------------+---------------+-----------------+----------+----------------+\n",
            "|sepal_length_scaled|sepal_width_scaled|petal_length_scaled|petal_width_scaled|label|            features|  rawPrediction|      probability|prediction|prediction_class|\n",
            "+-------------------+------------------+-------------------+------------------+-----+--------------------+---------------+-----------------+----------+----------------+\n",
            "|                0.0|             0.417|              0.017|               0.0|  0.0|[0.0,0.417,0.017,...|[125.0,0.0,0.0]|    [1.0,0.0,0.0]|       0.0|          Setosa|\n",
            "|              0.028|             0.417|              0.051|             0.042|  0.0|[0.028,0.417,0.05...|[125.0,0.0,0.0]|    [1.0,0.0,0.0]|       0.0|          Setosa|\n",
            "|              0.028|               0.5|              0.051|             0.042|  0.0|[0.028,0.5,0.051,...|[125.0,0.0,0.0]|    [1.0,0.0,0.0]|       0.0|          Setosa|\n",
            "|              0.056|             0.125|              0.051|             0.083|  0.0|[0.056,0.125,0.05...|[124.0,1.0,0.0]|[0.992,0.008,0.0]|       0.0|          Setosa|\n",
            "|              0.083|             0.458|              0.085|             0.042|  0.0|[0.083,0.458,0.08...|[125.0,0.0,0.0]|    [1.0,0.0,0.0]|       0.0|          Setosa|\n",
            "+-------------------+------------------+-------------------+------------------+-----+--------------------+---------------+-----------------+----------+----------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------------------+------------------+-------------------+------------------+-----+--------------------+--------------------+--------------------+----------+----------------+\n",
            "|sepal_length_scaled|sepal_width_scaled|petal_length_scaled|petal_width_scaled|label|            features|       rawPrediction|         probability|prediction|prediction_class|\n",
            "+-------------------+------------------+-------------------+------------------+-----+--------------------+--------------------+--------------------+----------+----------------+\n",
            "|              0.028|             0.375|              0.068|             0.042|  0.0|[0.028,0.375,0.06...|     [125.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|          Setosa|\n",
            "|              0.111|               0.5|              0.051|             0.042|  0.0|[0.111,0.5,0.051,...|     [125.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|          Setosa|\n",
            "|              0.139|             0.417|              0.068|             0.083|  0.0|[0.139,0.417,0.06...|     [125.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|          Setosa|\n",
            "|              0.167|             0.208|              0.593|             0.667|  2.0|[0.167,0.208,0.59...|[3.0,106.91866337...|[0.02399999999999...|       1.0|      Versicolor|\n",
            "|              0.194|               0.0|              0.424|             0.375|  1.0|[0.194,0.0,0.424,...|[2.0,108.94896640...|[0.01599999999999...|       1.0|      Versicolor|\n",
            "+-------------------+------------------+-------------------+------------------+-----+--------------------+--------------------+--------------------+----------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We can also use the multinomial family for binary classification\n",
        "index_to_class = [IndexToString(inputCol='prediction', outputCol='prediction_class', labels=i.labels) for i in indexers]\n",
        "\n",
        "model = Pipeline(stages=[\n",
        "  VectorAssembler(\n",
        "    inputCols=[f'{feature}_scaled' for feature in features],\n",
        "    outputCol='features'),\n",
        "  RandomForestClassifier(numTrees=125, maxDepth=5)\n",
        "] + index_to_class)\n",
        "\n",
        "# Fit the model\n",
        "model = model.fit(training)\n",
        "\n",
        "training_predictions = model.transform(training)\n",
        "testing_predictions = model.transform(testing)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "training_accuracy = evaluator.evaluate(training_predictions)\n",
        "testing_accuracy = evaluator.evaluate(testing_predictions)\n",
        "\n",
        "print(f'Train Accuracy: {str(training_accuracy)}')\n",
        "print(f'Train Error: {1.0 - training_accuracy}')\n",
        "\n",
        "print(f'Test Accuracy: {str(testing_accuracy)}')\n",
        "print(f'Test Error: {1.0 - testing_accuracy}')\n",
        "\n",
        "training_predictions.show(5)\n",
        "testing_predictions.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ATENCIÓN: PMML**\n",
        "\n",
        "Persistir el modelo es tan facil como hacer lo siguiente:"
      ],
      "metadata": {
        "id": "uT6YjItA4gsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q06LFyex7wZR",
        "outputId": "8df5e033-b0a0-4adb-c18c-dbeeab833120"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/RandomForestIris.pmml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "pmmlBuilder = PMMLBuilder(sc, training, model)\n",
        "pmmlBuilder.buildFile(\"RandomForestIris.pmml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Servir los modelos\n",
        "\n",
        "Con el próximo comando iniciamos un server llamado **OpenScoring**. Este es un servidor en Java que permite recibir el modelo como un request, y luego servirlo para poder hacer predicciones en tiempo real.\n",
        "\n",
        "OpenScoring no es el único servidor que permite servir modelos en tiempo real. También existe **MLeap**. Esta, aún más popular, es una librería open source para desplegar pipelines de datos y algoritmos sin necesidad de escribir más de 10 líneas de código. MLeap permite desplegar pipelines de Spark y Scikit-learn. Para este caso, MLeap utiliza un servidor Spring, también en Java, con la ejecución core en Scala."
      ],
      "metadata": {
        "id": "CNFlJSm66MlE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTmTL6xZPbDY",
        "outputId": "b8c19e26-539a-4c9e-b884-124a2e9102c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "!nohup java -jar /content/openscoring-server-executable-2.1.0.jar --port 8081 &\n",
        "!sleep 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Locallity o Localidad de la Data\n",
        "\n",
        "Las personas que diseñaron Spark notaron que es más costoeficiente \"mover los cómputos\" que \"mover la data\". Es decir, es más barato ejecutar los computos donde esta la data que mover la data a donde esta el computo. Por eso, no solamente Spark es procesamiento distribuido, sino que usa un patrón crucial para su funcionamiento óptimo. Este es, tener en cuenta la **Localidad de los datos**. Esto significa que los procesamientos que se envían al cluster de Spark, deben intentar poder ser performados por las máquinas en donde la data esta y evitar el *shuffling* (que los datos de una maquina termine en otra, que vimos que es costoso).\n",
        "\n",
        "Es importante tener esto en cuenta al momento de diseñar un sistema utilizando las tecnologías vistas en este colab. Se podría pensar en una arquitectura con los modelos desplegados en la misma máquina donde esta la data, de esta manera las consultas no saldrían de esta y sería extremadamente rápido, a pesar de que fuera HTTP.\n",
        "\n",
        "Los invito a considerar diferentes opciones y conversarlas en el discord."
      ],
      "metadata": {
        "id": "MaCUWqGV402n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X PUT --data-binary @RandomForestIris.pmml -H \"Content-type: text/xml\" http://localhost:8081/openscoring/model/RandomForestIris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wUzTVy18yvY",
        "outputId": "9233815f-689a-4559-e160-9464f174008e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\" : \"RandomForestIris\",\n",
            "  \"miningFunction\" : \"classification\",\n",
            "  \"summary\" : \"Ensemble model\",\n",
            "  \"properties\" : {\n",
            "    \"created.timestamp\" : \"2023-08-07T22:54:00.861+00:00\",\n",
            "    \"accessed.timestamp\" : null,\n",
            "    \"file.size\" : 289456,\n",
            "    \"file.checksum\" : \"3e832ab7062f2a490d8ccf6064c700e4d90e39cfd1bba6b1bd00b95f81cd6053\",\n",
            "    \"model.version\" : null\n",
            "  },\n",
            "  \"schema\" : {\n",
            "    \"inputFields\" : [ {\n",
            "      \"id\" : \"sepal_length_scaled\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"sepal_width_scaled\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"petal_length_scaled\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"petal_width_scaled\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    } ],\n",
            "    \"targetFields\" : [ {\n",
            "      \"id\" : \"label\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"categorical\",\n",
            "      \"values\" : [ \"0.0\", \"1.0\", \"2.0\" ]\n",
            "    } ],\n",
            "    \"outputFields\" : [ {\n",
            "      \"id\" : \"prediction\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"probability(0)\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"probability(1)\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    }, {\n",
            "      \"id\" : \"probability(2)\",\n",
            "      \"dataType\" : \"double\",\n",
            "      \"opType\" : \"continuous\"\n",
            "    } ]\n",
            "  }\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from json import dump\n",
        "\n",
        "evaluation = {\n",
        "    'id': 'record-001',\n",
        "    'arguments': {'sepal_length_scaled': 0.0, 'sepal_width_scaled': 0.417,\n",
        "             'petal_length_scaled': 0.017, 'petal_width_scaled': 0.0}\n",
        "}\n",
        "\n",
        "with open('test-data.json', 'w') as f:\n",
        "  dump(evaluation, f)"
      ],
      "metadata": {
        "id": "ucUkSbAf9KpY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST --data-binary @test-data.json -H \"Content-type: application/json\" http://localhost:8081/openscoring/model/RandomForestIris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK1AQ7o792en",
        "outputId": "f5ce7287-7873-4bc4-e8a2-4ac9f9eca981"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\" : \"record-001\",\n",
            "  \"results\" : {\n",
            "    \"label\" : 0.0,\n",
            "    \"prediction\" : 0.0,\n",
            "    \"probability(0)\" : 1.0,\n",
            "    \"probability(1)\" : 0.0,\n",
            "    \"probability(2)\" : 0.0\n",
            "  }\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menciones honorables\n",
        "\n",
        "- Tensorflow Extended\n",
        "- Tensorflow Serving\n",
        "- KubeFlow\n",
        "- ONNX\n",
        "- TensorRT"
      ],
      "metadata": {
        "id": "FqPITPdy_e3s"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}