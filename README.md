# Curso de Big Data con PySpark

Este curso proporciona una introducción completa a Big Data usando PySpark, la interfaz de Python para Apache Spark. El curso cubre una variedad de temas, incluyendo la arquitectura de Spark, las operaciones de datos distribuidos, el aprendizaje automático distribuido con Spark ML, y más.

## Contenido del Curso

### Clase 1: Introducción a PySpark y RDD

- Fundamentos teóricos, Spark Stack, arquitectura de Spark.
- Resilient Distributed Datasets (RDD), Transformaciones Narrow, Transformaciones Wide, Acciones.
- Operaciones en memoria caché (Persistencia, variables broadcast).
- Introducción a las Spark UI en Google Colab.
- Ejemplo práctico (SparkContext, SparkSession, RDD, Transformaciones, Acciones).
- [Adicional] ¿Qué hacer si la instalación por pip install falla?

### Clase 2: DataFrames y SQL en PySpark

- DataFrames en PySpark.
- Funciones definidas por el usuario (UDFs) y funciones agregadas definidas por el usuario (UDAFs) en Spark DataFrames.
- SparkSQL en PySpark.

### Clase 3: Aprendizaje automático distribuido con Spark ML

- Introducción al aprendizaje automático distribuido con Spark ML.

### Clase 4: Despliegue de Modelos y Streaming con Spark

- Despliegue de modelos MLlib para análisis en tiempo real.
- Introducción a Spark Streaming.


## Recursos Adicionales

- [Documentación oficial de PySpark](https://spark.apache.org/docs/latest/api/python/)
- [Guía de usuario de Spark](https://spark.apache.org/docs/latest/)
